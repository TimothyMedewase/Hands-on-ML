{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0)\n",
    "\n",
    "\n",
    "per_clf = Perceptron(random_state= 42)\n",
    "per_clf.fit(X, y)\n",
    "X_new = np.array([[2, 0.5], [3, 1]])\n",
    "y_pred = per_clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "housing= fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes= [50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053326657968762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an Image Classifier with the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train= X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid= X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the model using the sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01030841, -0.06164099,  0.05808872, ..., -0.06721644,\n",
       "        -0.00914722,  0.02773523],\n",
       "       [-0.01482046, -0.01720322,  0.06409074, ..., -0.02099765,\n",
       "        -0.05513718,  0.04648534],\n",
       "       [-0.05623198,  0.04789458, -0.01931117, ..., -0.02073532,\n",
       "         0.05105458,  0.06832398],\n",
       "       ...,\n",
       "       [-0.03145289, -0.02047037, -0.01450673, ...,  0.06472638,\n",
       "         0.06804311, -0.03750295],\n",
       "       [-0.05460898,  0.01333321,  0.04843942, ...,  0.06073408,\n",
       "        -0.0441385 , -0.04887902],\n",
       "       [-0.04136474,  0.06047811,  0.01107515, ...,  0.03107924,\n",
       "        -0.0179544 ,  0.00909407]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "#sparse_categorical_crossentropy is used because we have sparse labels, if we had one-hot vectors, we would use categorical_crossentropy\n",
    "#if we had binary classification, we would use sigmoid activation function and binary_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.6817 - loss: 1.0220 - val_accuracy: 0.8294 - val_loss: 0.5065\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8263 - loss: 0.5089 - val_accuracy: 0.8414 - val_loss: 0.4561\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.8417 - loss: 0.4556 - val_accuracy: 0.8474 - val_loss: 0.4318\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8524 - loss: 0.4244 - val_accuracy: 0.8528 - val_loss: 0.4159\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8597 - loss: 0.4024 - val_accuracy: 0.8544 - val_loss: 0.4034\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.8649 - loss: 0.3851 - val_accuracy: 0.8574 - val_loss: 0.3934\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8690 - loss: 0.3708 - val_accuracy: 0.8600 - val_loss: 0.3853\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8728 - loss: 0.3582 - val_accuracy: 0.8602 - val_loss: 0.3789\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8766 - loss: 0.3473 - val_accuracy: 0.8628 - val_loss: 0.3731\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8803 - loss: 0.3374 - val_accuracy: 0.8648 - val_loss: 0.3683\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.8834 - loss: 0.3285 - val_accuracy: 0.8666 - val_loss: 0.3638\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8859 - loss: 0.3202 - val_accuracy: 0.8676 - val_loss: 0.3599\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8884 - loss: 0.3126 - val_accuracy: 0.8684 - val_loss: 0.3566\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8906 - loss: 0.3054 - val_accuracy: 0.8682 - val_loss: 0.3543\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8928 - loss: 0.2986 - val_accuracy: 0.8686 - val_loss: 0.3535\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.8951 - loss: 0.2924 - val_accuracy: 0.8688 - val_loss: 0.3503\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8977 - loss: 0.2864 - val_accuracy: 0.8708 - val_loss: 0.3480\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8995 - loss: 0.2806 - val_accuracy: 0.8720 - val_loss: 0.3454\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.9005 - loss: 0.2752 - val_accuracy: 0.8736 - val_loss: 0.3447\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.9027 - loss: 0.2700 - val_accuracy: 0.8744 - val_loss: 0.3432\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.9050 - loss: 0.2648 - val_accuracy: 0.8732 - val_loss: 0.3453\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.9073 - loss: 0.2600 - val_accuracy: 0.8760 - val_loss: 0.3421\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.9094 - loss: 0.2551 - val_accuracy: 0.8746 - val_loss: 0.3426\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.9112 - loss: 0.2506 - val_accuracy: 0.8748 - val_loss: 0.3432\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.9127 - loss: 0.2463 - val_accuracy: 0.8770 - val_loss: 0.3428\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.9145 - loss: 0.2421 - val_accuracy: 0.8762 - val_loss: 0.3403\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.9158 - loss: 0.2379 - val_accuracy: 0.8766 - val_loss: 0.3394\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9171 - loss: 0.2338 - val_accuracy: 0.8774 - val_loss: 0.3384\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.9184 - loss: 0.2299 - val_accuracy: 0.8772 - val_loss: 0.3383\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.9203 - loss: 0.2260 - val_accuracy: 0.8778 - val_loss: 0.3373\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5), xlim=[0,29], ylim=[0,1], grid=True, xlabel=\"Epoch\", style=['r--','r--.','b-', 'b-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8752 - loss: 0.3602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3567982017993927, 0.8741999864578247]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.01, 0.  , 0.8 ],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred= y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a Regression MLP using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - RootMeanSquaredError: 1.2586 - loss: 1.7072 - val_RootMeanSquaredError: 0.6205 - val_loss: 0.3850\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - RootMeanSquaredError: 0.6325 - loss: 0.4005 - val_RootMeanSquaredError: 0.6975 - val_loss: 0.4865\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - RootMeanSquaredError: 0.6007 - loss: 0.3610 - val_RootMeanSquaredError: 0.9206 - val_loss: 0.8475\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - RootMeanSquaredError: 0.5866 - loss: 0.3442 - val_RootMeanSquaredError: 0.8953 - val_loss: 0.8016\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - RootMeanSquaredError: 0.5748 - loss: 0.3306 - val_RootMeanSquaredError: 1.0530 - val_loss: 1.1089\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - RootMeanSquaredError: 0.5671 - loss: 0.3217 - val_RootMeanSquaredError: 1.1277 - val_loss: 1.2718\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5601 - loss: 0.3138 - val_RootMeanSquaredError: 1.6267 - val_loss: 2.6460\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - RootMeanSquaredError: 0.5580 - loss: 0.3115 - val_RootMeanSquaredError: 0.9183 - val_loss: 0.8433\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - RootMeanSquaredError: 0.5505 - loss: 0.3031 - val_RootMeanSquaredError: 1.3938 - val_loss: 1.9427\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - RootMeanSquaredError: 0.5474 - loss: 0.2997 - val_RootMeanSquaredError: 0.8446 - val_loss: 0.7134\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - RootMeanSquaredError: 0.5419 - loss: 0.2937 - val_RootMeanSquaredError: 1.0280 - val_loss: 1.0568\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - RootMeanSquaredError: 0.5388 - loss: 0.2903 - val_RootMeanSquaredError: 0.6738 - val_loss: 0.4540\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5338 - loss: 0.2850 - val_RootMeanSquaredError: 0.6499 - val_loss: 0.4223\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - RootMeanSquaredError: 0.5293 - loss: 0.2803 - val_RootMeanSquaredError: 0.5312 - val_loss: 0.2821\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5260 - loss: 0.2768 - val_RootMeanSquaredError: 0.6111 - val_loss: 0.3734\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - RootMeanSquaredError: 0.5230 - loss: 0.2736 - val_RootMeanSquaredError: 0.5220 - val_loss: 0.2724\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - RootMeanSquaredError: 0.5202 - loss: 0.2707 - val_RootMeanSquaredError: 0.6375 - val_loss: 0.4064\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - RootMeanSquaredError: 0.5180 - loss: 0.2684 - val_RootMeanSquaredError: 0.5178 - val_loss: 0.2682\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - RootMeanSquaredError: 0.5158 - loss: 0.2661 - val_RootMeanSquaredError: 0.6357 - val_loss: 0.4041\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - RootMeanSquaredError: 0.5138 - loss: 0.2640 - val_RootMeanSquaredError: 0.5656 - val_loss: 0.3199\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209us/step - RootMeanSquaredError: 0.5292 - loss: 0.2802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model= tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a Regression MLP using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │ normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m270\u001b[0m │ normalization_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m930\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ normalization_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m39\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,256</span> (4.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,256\u001b[0m (4.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,239</span> (4.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,239\u001b[0m (4.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - RootMeanSquaredError: 1.6151 - loss: 2.7429 - val_RootMeanSquaredError: 0.7466 - val_loss: 0.5574\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - RootMeanSquaredError: 0.7252 - loss: 0.5269 - val_RootMeanSquaredError: 1.3427 - val_loss: 1.8030\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - RootMeanSquaredError: 0.6541 - loss: 0.4282 - val_RootMeanSquaredError: 0.9822 - val_loss: 0.9648\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - RootMeanSquaredError: 0.6331 - loss: 0.4011 - val_RootMeanSquaredError: 1.6437 - val_loss: 2.7016\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - RootMeanSquaredError: 0.6215 - loss: 0.3865 - val_RootMeanSquaredError: 1.3929 - val_loss: 1.9403\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.6152 - loss: 0.3786 - val_RootMeanSquaredError: 1.5583 - val_loss: 2.4283\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - RootMeanSquaredError: 0.6101 - loss: 0.3723 - val_RootMeanSquaredError: 1.1853 - val_loss: 1.4050\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - RootMeanSquaredError: 0.6034 - loss: 0.3642 - val_RootMeanSquaredError: 1.2777 - val_loss: 1.6325\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.5999 - loss: 0.3600 - val_RootMeanSquaredError: 0.9824 - val_loss: 0.9652\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - RootMeanSquaredError: 0.5946 - loss: 0.3537 - val_RootMeanSquaredError: 1.1023 - val_loss: 1.2151\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.5909 - loss: 0.3493 - val_RootMeanSquaredError: 0.9085 - val_loss: 0.8254\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.5884 - loss: 0.3463 - val_RootMeanSquaredError: 1.2492 - val_loss: 1.5604\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.5874 - loss: 0.3451 - val_RootMeanSquaredError: 1.0543 - val_loss: 1.1116\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - RootMeanSquaredError: 0.5837 - loss: 0.3408 - val_RootMeanSquaredError: 1.2695 - val_loss: 1.6117\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - RootMeanSquaredError: 0.5819 - loss: 0.3387 - val_RootMeanSquaredError: 1.1899 - val_loss: 1.4159\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - RootMeanSquaredError: 0.5788 - loss: 0.3351 - val_RootMeanSquaredError: 1.3653 - val_loss: 1.8640\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - RootMeanSquaredError: 0.5775 - loss: 0.3336 - val_RootMeanSquaredError: 1.0373 - val_loss: 1.0759\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - RootMeanSquaredError: 0.5721 - loss: 0.3273 - val_RootMeanSquaredError: 1.0462 - val_loss: 1.0946\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - RootMeanSquaredError: 0.5695 - loss: 0.3244 - val_RootMeanSquaredError: 0.8429 - val_loss: 0.7105\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - RootMeanSquaredError: 0.5674 - loss: 0.3220 - val_RootMeanSquaredError: 0.9302 - val_loss: 0.8652\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200us/step - RootMeanSquaredError: 0.5626 - loss: 0.3167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "normalization_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending different inputs through different paths\n",
    "\n",
    "input_wide = tf.keras.layers.Input(shape=[5])\n",
    "input_deep = tf.keras.layers.Input(shape=[6])\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - RootMeanSquaredError: 1.5785 - loss: 2.6009 - val_RootMeanSquaredError: 2.0923 - val_loss: 4.3779\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - RootMeanSquaredError: 0.7291 - loss: 0.5321 - val_RootMeanSquaredError: 1.1580 - val_loss: 1.3411\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - RootMeanSquaredError: 0.6697 - loss: 0.4486 - val_RootMeanSquaredError: 0.8073 - val_loss: 0.6517\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - RootMeanSquaredError: 0.6485 - loss: 0.4208 - val_RootMeanSquaredError: 0.6543 - val_loss: 0.4280\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - RootMeanSquaredError: 0.6349 - loss: 0.4033 - val_RootMeanSquaredError: 0.6222 - val_loss: 0.3871\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - RootMeanSquaredError: 0.6238 - loss: 0.3893 - val_RootMeanSquaredError: 0.5897 - val_loss: 0.3477\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - RootMeanSquaredError: 0.6146 - loss: 0.3779 - val_RootMeanSquaredError: 0.6084 - val_loss: 0.3702\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - RootMeanSquaredError: 0.6076 - loss: 0.3693 - val_RootMeanSquaredError: 0.5906 - val_loss: 0.3488\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - RootMeanSquaredError: 0.6016 - loss: 0.3620 - val_RootMeanSquaredError: 0.7468 - val_loss: 0.5577\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - RootMeanSquaredError: 0.5981 - loss: 0.3578 - val_RootMeanSquaredError: 0.6480 - val_loss: 0.4199\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - RootMeanSquaredError: 0.5930 - loss: 0.3517 - val_RootMeanSquaredError: 0.8309 - val_loss: 0.6903\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - RootMeanSquaredError: 0.5908 - loss: 0.3491 - val_RootMeanSquaredError: 0.9638 - val_loss: 0.9288\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - RootMeanSquaredError: 0.5881 - loss: 0.3459 - val_RootMeanSquaredError: 1.3400 - val_loss: 1.7955\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - RootMeanSquaredError: 0.5869 - loss: 0.3445 - val_RootMeanSquaredError: 1.1690 - val_loss: 1.3666\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - RootMeanSquaredError: 0.5837 - loss: 0.3408 - val_RootMeanSquaredError: 0.9684 - val_loss: 0.9379\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - RootMeanSquaredError: 0.5802 - loss: 0.3367 - val_RootMeanSquaredError: 0.7638 - val_loss: 0.5834\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - RootMeanSquaredError: 0.5763 - loss: 0.3321 - val_RootMeanSquaredError: 0.7292 - val_loss: 0.5317\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - RootMeanSquaredError: 0.5742 - loss: 0.3298 - val_RootMeanSquaredError: 0.6745 - val_loss: 0.4549\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - RootMeanSquaredError: 0.5722 - loss: 0.3275 - val_RootMeanSquaredError: 0.7126 - val_loss: 0.5078\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - RootMeanSquaredError: 0.5706 - loss: 0.3256 - val_RootMeanSquaredError: 0.7722 - val_loss: 0.5963\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - RootMeanSquaredError: 0.5739 - loss: 0.3294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=20, validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])\n",
    "input_deep = tf.keras.layers.Input(shape=[6])\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output, aux_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer, metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - dense_2_RootMeanSquaredError: 1.4617 - dense_3_RootMeanSquaredError: 1.7473 - loss: 2.3205 - val_dense_2_RootMeanSquaredError: 0.8158 - val_dense_3_RootMeanSquaredError: 2.2849 - val_loss: 1.1211\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - dense_2_RootMeanSquaredError: 0.7023 - dense_3_RootMeanSquaredError: 0.9302 - loss: 0.5310 - val_dense_2_RootMeanSquaredError: 0.6379 - val_dense_3_RootMeanSquaredError: 0.9191 - val_loss: 0.4507\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - dense_2_RootMeanSquaredError: 0.6634 - dense_3_RootMeanSquaredError: 0.8029 - loss: 0.4607 - val_dense_2_RootMeanSquaredError: 0.9115 - val_dense_3_RootMeanSquaredError: 0.8113 - val_loss: 0.8136\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - dense_2_RootMeanSquaredError: 0.6491 - dense_3_RootMeanSquaredError: 0.7749 - loss: 0.4395 - val_dense_2_RootMeanSquaredError: 0.6406 - val_dense_3_RootMeanSquaredError: 0.8213 - val_loss: 0.4368\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - dense_2_RootMeanSquaredError: 0.6375 - dense_3_RootMeanSquaredError: 0.7577 - loss: 0.4234 - val_dense_2_RootMeanSquaredError: 1.1943 - val_dense_3_RootMeanSquaredError: 0.7974 - val_loss: 1.3472\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - dense_2_RootMeanSquaredError: 0.6288 - dense_3_RootMeanSquaredError: 0.7426 - loss: 0.4112 - val_dense_2_RootMeanSquaredError: 1.6540 - val_dense_3_RootMeanSquaredError: 1.3356 - val_loss: 2.6404\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - dense_2_RootMeanSquaredError: 0.6227 - dense_3_RootMeanSquaredError: 0.7273 - loss: 0.4020 - val_dense_2_RootMeanSquaredError: 1.6736 - val_dense_3_RootMeanSquaredError: 1.0196 - val_loss: 2.6248\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - dense_2_RootMeanSquaredError: 0.6125 - dense_3_RootMeanSquaredError: 0.7123 - loss: 0.3885 - val_dense_2_RootMeanSquaredError: 1.8040 - val_dense_3_RootMeanSquaredError: 1.2248 - val_loss: 3.0790\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - dense_2_RootMeanSquaredError: 0.6068 - dense_3_RootMeanSquaredError: 0.6959 - loss: 0.3800 - val_dense_2_RootMeanSquaredError: 2.0053 - val_dense_3_RootMeanSquaredError: 0.6721 - val_loss: 3.6641\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - dense_2_RootMeanSquaredError: 0.6039 - dense_3_RootMeanSquaredError: 0.6859 - loss: 0.3754 - val_dense_2_RootMeanSquaredError: 1.5823 - val_dense_3_RootMeanSquaredError: 2.0390 - val_loss: 2.6690\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - dense_2_RootMeanSquaredError: 0.5953 - dense_3_RootMeanSquaredError: 0.6769 - loss: 0.3649 - val_dense_2_RootMeanSquaredError: 1.6448 - val_dense_3_RootMeanSquaredError: 0.8964 - val_loss: 2.5152\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - dense_2_RootMeanSquaredError: 0.5930 - dense_3_RootMeanSquaredError: 0.6640 - loss: 0.3607 - val_dense_2_RootMeanSquaredError: 1.5585 - val_dense_3_RootMeanSquaredError: 1.7173 - val_loss: 2.4810\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - dense_2_RootMeanSquaredError: 0.5888 - dense_3_RootMeanSquaredError: 0.6608 - loss: 0.3558 - val_dense_2_RootMeanSquaredError: 1.3534 - val_dense_3_RootMeanSquaredError: 1.0456 - val_loss: 1.7579\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - dense_2_RootMeanSquaredError: 0.5848 - dense_3_RootMeanSquaredError: 0.6520 - loss: 0.3504 - val_dense_2_RootMeanSquaredError: 1.4358 - val_dense_3_RootMeanSquaredError: 1.5244 - val_loss: 2.0877\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - dense_2_RootMeanSquaredError: 0.5819 - dense_3_RootMeanSquaredError: 0.6475 - loss: 0.3467 - val_dense_2_RootMeanSquaredError: 1.3412 - val_dense_3_RootMeanSquaredError: 0.9721 - val_loss: 1.7134\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - dense_2_RootMeanSquaredError: 0.5807 - dense_3_RootMeanSquaredError: 0.6435 - loss: 0.3450 - val_dense_2_RootMeanSquaredError: 1.5043 - val_dense_3_RootMeanSquaredError: 1.4646 - val_loss: 2.2511\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - dense_2_RootMeanSquaredError: 0.5791 - dense_3_RootMeanSquaredError: 0.6399 - loss: 0.3429 - val_dense_2_RootMeanSquaredError: 1.3854 - val_dense_3_RootMeanSquaredError: 0.9446 - val_loss: 1.8167\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - dense_2_RootMeanSquaredError: 0.5779 - dense_3_RootMeanSquaredError: 0.6369 - loss: 0.3412 - val_dense_2_RootMeanSquaredError: 1.7133 - val_dense_3_RootMeanSquaredError: 1.9513 - val_loss: 3.0227\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - dense_2_RootMeanSquaredError: 0.5787 - dense_3_RootMeanSquaredError: 0.6388 - loss: 0.3423 - val_dense_2_RootMeanSquaredError: 1.6071 - val_dense_3_RootMeanSquaredError: 1.3121 - val_loss: 2.4965\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - dense_2_RootMeanSquaredError: 0.5777 - dense_3_RootMeanSquaredError: 0.6348 - loss: 0.3408 - val_dense_2_RootMeanSquaredError: 1.4641 - val_dense_3_RootMeanSquaredError: 1.1530 - val_loss: 2.0621\n"
     ]
    }
   ],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245us/step - dense_2_RootMeanSquaredError: 0.5808 - dense_3_RootMeanSquaredError: 0.6358 - loss: 0.3441\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x31c1f8fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip([\"main_output\", \"aux_output\"], y_pred_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\", name=\"wide_and_deep_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - RootMeanSquaredError: 1.4084 - RootMeanSquaredError_1: 1.8601 - loss: 2.2081 - val_RootMeanSquaredError: 1.0812 - val_RootMeanSquaredError_1: 1.8856 - val_loss: 1.4076\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - RootMeanSquaredError: 0.7324 - RootMeanSquaredError_1: 0.8808 - loss: 0.5608 - val_RootMeanSquaredError: 0.6590 - val_RootMeanSquaredError_1: 1.0478 - val_loss: 0.5006\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - RootMeanSquaredError: 0.6760 - RootMeanSquaredError_1: 0.7878 - loss: 0.4736 - val_RootMeanSquaredError: 0.6331 - val_RootMeanSquaredError_1: 0.8364 - val_loss: 0.4306\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - RootMeanSquaredError: 0.6504 - RootMeanSquaredError_1: 0.7597 - loss: 0.4386 - val_RootMeanSquaredError: 0.6116 - val_RootMeanSquaredError_1: 0.7394 - val_loss: 0.3913\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - RootMeanSquaredError: 0.6333 - RootMeanSquaredError_1: 0.7397 - loss: 0.4158 - val_RootMeanSquaredError: 0.5959 - val_RootMeanSquaredError_1: 0.7217 - val_loss: 0.3716\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - RootMeanSquaredError: 0.6214 - RootMeanSquaredError_1: 0.7242 - loss: 0.4002 - val_RootMeanSquaredError: 0.6033 - val_RootMeanSquaredError_1: 0.6937 - val_loss: 0.3757\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - RootMeanSquaredError: 0.6130 - RootMeanSquaredError_1: 0.7100 - loss: 0.3887 - val_RootMeanSquaredError: 0.5794 - val_RootMeanSquaredError_1: 0.6884 - val_loss: 0.3496\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - RootMeanSquaredError: 0.6061 - RootMeanSquaredError_1: 0.6950 - loss: 0.3791 - val_RootMeanSquaredError: 0.7086 - val_RootMeanSquaredError_1: 0.7015 - val_loss: 0.5011\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - RootMeanSquaredError: 0.6012 - RootMeanSquaredError_1: 0.6847 - loss: 0.3723 - val_RootMeanSquaredError: 0.6471 - val_RootMeanSquaredError_1: 0.7417 - val_loss: 0.4318\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - RootMeanSquaredError: 0.5974 - RootMeanSquaredError_1: 0.6728 - loss: 0.3665 - val_RootMeanSquaredError: 1.0569 - val_RootMeanSquaredError_1: 0.9279 - val_loss: 1.0913\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step - RootMeanSquaredError: 0.5933 - RootMeanSquaredError_1: 0.6608 - loss: 0.3605\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x31e04a020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=optimizer, metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"])\n",
    "model.norm_layer_wide.adapt(X_train_wide)\n",
    "model.norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit((X_train_wide, X_train_deep), (y_train, y_train), epochs=10, validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)))\n",
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"my_keras_model\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_keras_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_keras_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'my_keras_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): Tuple[TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)]\n",
      "Output Type:\n",
      "  Tuple[TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  13343087056: TensorSpec(shape=(1, 5), dtype=tf.float32, name=None)\n",
      "  13343094352: TensorSpec(shape=(1, 5), dtype=tf.float32, name=None)\n",
      "  13331111888: TensorSpec(shape=(1, 6), dtype=tf.float32, name=None)\n",
      "  13331107856: TensorSpec(shape=(1, 6), dtype=tf.float32, name=None)\n",
      "  13331117456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331119568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331118992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331119952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331119376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331119760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331119184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13331117264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"my_keras_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_keras_model/assets\n",
      "my_keras_model/fingerprint.pb\n",
      "my_keras_model/saved_model.pb\n",
      "my_keras_model/variables\n",
      "my_keras_model/variables/variables.data-00000-of-00001\n",
      "my_keras_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for path in sorted(Path(\"my_keras_model\").glob(\"**/*\")):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfsm_layer = tf.keras.layers.TFSMLayer(\"my_keras_model\")\n",
    "y_pred_main, y_pred_aux = tfsm_layer((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"my_weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"my_model.keras\", custom_objects={\"WideAndDeepModel\": WideAndDeepModel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"my_checkpoints\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - RootMeanSquaredError: 0.5937 - RootMeanSquaredError_1: 0.6654 - loss: 0.3616 - val_RootMeanSquaredError: 1.0858 - val_RootMeanSquaredError_1: 1.2327 - val_loss: 1.2130\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - RootMeanSquaredError: 0.5927 - RootMeanSquaredError_1: 0.6607 - loss: 0.3599 - val_RootMeanSquaredError: 1.5567 - val_RootMeanSquaredError_1: 1.5125 - val_loss: 2.4099\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - RootMeanSquaredError: 0.5925 - RootMeanSquaredError_1: 0.6563 - loss: 0.3591 - val_RootMeanSquaredError: 1.0373 - val_RootMeanSquaredError_1: 1.1291 - val_loss: 1.0959\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - RootMeanSquaredError: 0.5869 - RootMeanSquaredError_1: 0.6485 - loss: 0.3522 - val_RootMeanSquaredError: 0.6110 - val_RootMeanSquaredError_1: 0.6386 - val_loss: 0.3767\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - RootMeanSquaredError: 0.5825 - RootMeanSquaredError_1: 0.6430 - loss: 0.3468 - val_RootMeanSquaredError: 0.5666 - val_RootMeanSquaredError_1: 0.6608 - val_loss: 0.3327\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - RootMeanSquaredError: 0.5803 - RootMeanSquaredError_1: 0.6377 - loss: 0.3439 - val_RootMeanSquaredError: 0.5755 - val_RootMeanSquaredError_1: 0.6242 - val_loss: 0.3370\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - RootMeanSquaredError: 0.5784 - RootMeanSquaredError_1: 0.6342 - loss: 0.3414 - val_RootMeanSquaredError: 0.5690 - val_RootMeanSquaredError_1: 0.6652 - val_loss: 0.3356\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - RootMeanSquaredError: 0.5768 - RootMeanSquaredError_1: 0.6318 - loss: 0.3395 - val_RootMeanSquaredError: 0.6347 - val_RootMeanSquaredError_1: 0.6614 - val_loss: 0.4063\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - RootMeanSquaredError: 0.5750 - RootMeanSquaredError_1: 0.6275 - loss: 0.3370 - val_RootMeanSquaredError: 0.6504 - val_RootMeanSquaredError_1: 0.8205 - val_loss: 0.4481\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - RootMeanSquaredError: 0.5745 - RootMeanSquaredError_1: 0.6269 - loss: 0.3364 - val_RootMeanSquaredError: 1.0610 - val_RootMeanSquaredError_1: 1.1442 - val_loss: 1.1441\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints.weights.h5\",\n",
    "                                                   save_weights_only=True)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - RootMeanSquaredError: 0.5747 - RootMeanSquaredError_1: 0.6260 - loss: 0.3366 - val_RootMeanSquaredError: 0.9944 - val_RootMeanSquaredError_1: 1.2908 - val_loss: 1.0565\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - RootMeanSquaredError: 0.5732 - RootMeanSquaredError_1: 0.6237 - loss: 0.3347 - val_RootMeanSquaredError: 0.6335 - val_RootMeanSquaredError_1: 0.6436 - val_loss: 0.4026\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - RootMeanSquaredError: 0.5700 - RootMeanSquaredError_1: 0.6180 - loss: 0.3307 - val_RootMeanSquaredError: 0.7074 - val_RootMeanSquaredError_1: 0.8576 - val_loss: 0.5239\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - RootMeanSquaredError: 0.5683 - RootMeanSquaredError_1: 0.6169 - loss: 0.3288 - val_RootMeanSquaredError: 0.7472 - val_RootMeanSquaredError_1: 0.8439 - val_loss: 0.5737\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - RootMeanSquaredError: 0.5673 - RootMeanSquaredError_1: 0.6141 - loss: 0.3274 - val_RootMeanSquaredError: 0.9657 - val_RootMeanSquaredError_1: 1.1358 - val_loss: 0.9684\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - RootMeanSquaredError: 0.5665 - RootMeanSquaredError_1: 0.6141 - loss: 0.3267 - val_RootMeanSquaredError: 0.6968 - val_RootMeanSquaredError_1: 0.6902 - val_loss: 0.4846\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - RootMeanSquaredError: 0.5648 - RootMeanSquaredError_1: 0.6100 - loss: 0.3243 - val_RootMeanSquaredError: 0.6652 - val_RootMeanSquaredError_1: 0.9184 - val_loss: 0.4825\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - RootMeanSquaredError: 0.5642 - RootMeanSquaredError_1: 0.6107 - loss: 0.3238 - val_RootMeanSquaredError: 0.7424 - val_RootMeanSquaredError_1: 0.9233 - val_loss: 0.5813\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - RootMeanSquaredError: 0.5632 - RootMeanSquaredError_1: 0.6077 - loss: 0.3225 - val_RootMeanSquaredError: 0.7473 - val_RootMeanSquaredError_1: 1.0132 - val_loss: 0.6053\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - RootMeanSquaredError: 0.5619 - RootMeanSquaredError_1: 0.6067 - loss: 0.3210 - val_RootMeanSquaredError: 0.7012 - val_RootMeanSquaredError_1: 0.9037 - val_loss: 0.5242\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - RootMeanSquaredError: 0.5607 - RootMeanSquaredError_1: 0.6045 - loss: 0.3195 - val_RootMeanSquaredError: 0.7963 - val_RootMeanSquaredError_1: 0.9034 - val_loss: 0.6522\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - RootMeanSquaredError: 0.5599 - RootMeanSquaredError_1: 0.6028 - loss: 0.3185 - val_RootMeanSquaredError: 0.6418 - val_RootMeanSquaredError_1: 0.7271 - val_loss: 0.4235\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=100,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display ration between validation and training loss\n",
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    run_id = strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    return Path(root_logdir) / run_id\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using TensorBoard for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 20:09:35.046141: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-12-01 20:09:35.046149: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2024-12-01 20:09:35.046318: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - RootMeanSquaredError: 1.8646 - loss: 3.5730 - val_RootMeanSquaredError: 1.0039 - val_loss: 1.0079\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 20:09:35.388536: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-12-01 20:09:35.388549: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2024-12-01 20:09:35.425944: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
      "2024-12-01 20:09:35.436220: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2024-12-01 20:09:35.438004: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: my_logs/run_2024_12_01_20_09_34/plugins/profile/2024_12_01_20_09_35/Timothys-MacBook-Air.local.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - RootMeanSquaredError: 0.9330 - loss: 0.8718 - val_RootMeanSquaredError: 0.8182 - val_loss: 0.6694\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - RootMeanSquaredError: 0.8464 - loss: 0.7176 - val_RootMeanSquaredError: 0.7737 - val_loss: 0.5985\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - RootMeanSquaredError: 0.8025 - loss: 0.6451 - val_RootMeanSquaredError: 0.7522 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - RootMeanSquaredError: 0.7707 - loss: 0.5951 - val_RootMeanSquaredError: 0.7280 - val_loss: 0.5300\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - RootMeanSquaredError: 0.7460 - loss: 0.5574 - val_RootMeanSquaredError: 0.7056 - val_loss: 0.4979\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - RootMeanSquaredError: 0.7262 - loss: 0.5282 - val_RootMeanSquaredError: 0.6866 - val_loss: 0.4714\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - RootMeanSquaredError: 0.7099 - loss: 0.5047 - val_RootMeanSquaredError: 0.6702 - val_loss: 0.4492\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - RootMeanSquaredError: 0.6966 - loss: 0.4859 - val_RootMeanSquaredError: 0.6563 - val_loss: 0.4307\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - RootMeanSquaredError: 0.6855 - loss: 0.4705 - val_RootMeanSquaredError: 0.6456 - val_loss: 0.4167\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - RootMeanSquaredError: 0.6762 - loss: 0.4578 - val_RootMeanSquaredError: 0.6373 - val_loss: 0.4062\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - RootMeanSquaredError: 0.6684 - loss: 0.4472 - val_RootMeanSquaredError: 0.6311 - val_loss: 0.3983\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - RootMeanSquaredError: 0.6619 - loss: 0.4385 - val_RootMeanSquaredError: 0.6265 - val_loss: 0.3925\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - RootMeanSquaredError: 0.6562 - loss: 0.4311 - val_RootMeanSquaredError: 0.6227 - val_loss: 0.3878\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - RootMeanSquaredError: 0.6514 - loss: 0.4247 - val_RootMeanSquaredError: 0.6199 - val_loss: 0.3843\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - RootMeanSquaredError: 0.6472 - loss: 0.4192 - val_RootMeanSquaredError: 0.6178 - val_loss: 0.3816\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - RootMeanSquaredError: 0.6434 - loss: 0.4144 - val_RootMeanSquaredError: 0.6161 - val_loss: 0.3796\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - RootMeanSquaredError: 0.6401 - loss: 0.4100 - val_RootMeanSquaredError: 0.6150 - val_loss: 0.3782\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - RootMeanSquaredError: 0.6370 - loss: 0.4061 - val_RootMeanSquaredError: 0.6137 - val_loss: 0.3767\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - RootMeanSquaredError: 0.6342 - loss: 0.4025 - val_RootMeanSquaredError: 0.6129 - val_loss: 0.3757\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, profile_batch=(100, 200))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_logs\n",
      "  run_2024_12_01_19_20_17\n",
      "    plugins\n",
      "      profile\n",
      "        2024_12_01_19_24_13\n",
      "          Timothys-MacBook-Air.local.xplane.pb\n",
      "    train\n",
      "      events.out.tfevents.1733102653.Timothys-MacBook-Air.local.78096.0.v2\n",
      "    validation\n",
      "      events.out.tfevents.1733102653.Timothys-MacBook-Air.local.78096.1.v2\n",
      "  run_2024_12_01_19_44_44\n",
      "    events.out.tfevents.1733103884.Timothys-MacBook-Air.local.78096.2.v2\n",
      "  run_2024_12_01_20_09_34\n",
      "    plugins\n",
      "      profile\n",
      "        2024_12_01_20_09_35\n",
      "          Timothys-MacBook-Air.local.xplane.pb\n",
      "    train\n",
      "      events.out.tfevents.1733105375.Timothys-MacBook-Air.local.83729.0.v2\n",
      "    validation\n",
      "      events.out.tfevents.1733105375.Timothys-MacBook-Air.local.83729.1.v2\n"
     ]
    }
   ],
   "source": [
    "print(\"my_logs\")\n",
    "for path in sorted(Path(\"my_logs\").glob(\"**/*\")):\n",
    "    print(\"  \" * (len(path.parts) - 1) + path.parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(str(test_logdir))\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        \n",
    "        data = (np.random.randn(100) + 2) * step / 100  # gets larger\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        \n",
    "        images = np.random.rand(2, 32, 32, 3) * step / 1000  # gets brighter\n",
    "        tf.summary.image(\"my_images\", images, step=step)\n",
    "        \n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step ** 2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        \n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir ./my_logs (started 0:35:45 ago; pid 83143)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.8353999853134155\n",
      "\n",
      "Best val_accuracy So Far: 0.8640000224113464\n",
      "Total elapsed time: 00h 00m 51s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 8,\n",
       " 'n_neurons': 37,\n",
       " 'learning_rate': 0.008547485565344062,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 8\n",
      "n_neurons: 37\n",
      "learning_rate: 0.008547485565344062\n",
      "optimizer: sgd\n",
      "Score: 0.8640000224113464\n"
     ]
    }
   ],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640000224113464"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - accuracy: 0.8692 - loss: 0.3567\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - accuracy: 0.8714 - loss: 0.3479\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - accuracy: 0.8730 - loss: 0.3404\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step - accuracy: 0.8745 - loss: 0.3345\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345us/step - accuracy: 0.8779 - loss: 0.3276\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step - accuracy: 0.8795 - loss: 0.3247\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353us/step - accuracy: 0.8812 - loss: 0.3213\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369us/step - accuracy: 0.8831 - loss: 0.3146\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - accuracy: 0.8845 - loss: 0.3103\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - accuracy: 0.8852 - loss: 0.3091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3472cad50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8522 - loss: 0.4125\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "    \n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)\n",
    "\n",
    "#hyperband_tuner-keeps only the top 1/factor models, repeating until a single model is left\n",
    "#total number of epochs for each hyperband iteration is max_epochs * (log(max_epochs)/log(factor)) **2\n",
    "hyperband_tuner = kt.Hyperband(\n",
    "    MyClassificationHyperModel(),objective=\"val_accuracy\", seed=42,\n",
    "    max_epochs=10, factor=3, hyperband_iterations=2, overwrite=True, directory=\"my_fashion_mnist\", project_name=\"hyperband\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 13s]\n",
      "val_accuracy: 0.8384000062942505\n",
      "\n",
      "Best val_accuracy So Far: 0.8754000067710876\n",
      "Total elapsed time: 00h 06m 43s\n"
     ]
    }
   ],
   "source": [
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(X_train, y_train, epochs=10,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[early_stopping_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.8303999900817871\n",
      "\n",
      "Best val_accuracy So Far: 0.854200005531311\n",
      "Total elapsed time: 00h 01m 47s\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(MyClassificationHyperModel(), objective= \"val_accuracy\", max_trials=10, seed=42, alpha= 1e-4, beta= 2.6, overwrite=True, directory=\"my_fashion_mnist\", project_name=\"bayesian_opt\")\n",
    "bayesian_opt_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
